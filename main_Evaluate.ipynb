{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model evaluation (YoloV8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.36  Python-3.9.12 torch-1.13.1+cu117 CPU\n",
      "Setup complete  (8 CPUs, 15.7 GB RAM, 420.1/476.3 GB disk)\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "from IPython.display import display, Image\n",
    "import os\n",
    "\n",
    "from IPython import display\n",
    "display.clear_output()\n",
    "\n",
    "import ultralytics\n",
    "ultralytics.checks()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\D\\D\\User\\PythonProject\\deep_plastic_YoloV8\n"
     ]
    }
   ],
   "source": [
    "HOME = os.getcwd()\n",
    "print(HOME)\n",
    "\n",
    "model= YOLO(f'{HOME}/checkpoints/trained_weights/Vietnam_3_class_V4_original/weights/best.pt')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test model on a test datset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save test results in a folder\n",
    "# Note: this folder will be generated automatically,\n",
    "#       do not create it in advance\n",
    "save_test_path = r\"/scratch/tjian/PythonProject/deep_plastic_YoloV8/checkpoints/trained_weights/Oos80per/test_results/\"\n",
    "\n",
    "\n",
    "model.val(\n",
    "    data=\"Data/Vietnam_3_class_test.yaml\",\n",
    "    imgsz=640,\n",
    "    conf=0.5, # (default 0.25 predict)\n",
    "    save=True,\n",
    "    name=save_test_path,\n",
    "    plots=True\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict images in a folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source_path = r\"U:\\AIMMW\\Amsterdam_with_Paolo\\Data\\Data_HUAWEI_Phone\"\n",
    "source_path = r\"U:\\AIMMW\\Vietnam\\Vietnam_3_class_V4_original\\test\\images\"\n",
    "\n",
    "save_test_images_path = r\"C:\\D\\D\\User\\PythonProject\\deep_plastic_YoloV8\\checkpoints\\trained_weights\\Vietnam_3_class_V4_original\\img_pred_test\"\n",
    "\n",
    "results = model.predict(\n",
    "    source = source_path,\n",
    "    conf=0.5, # (default 0.25 predict)\n",
    "    save=True,\n",
    "    name=save_test_images_path\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict images on a video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.predict(\n",
    "    source=r\"U:\\AIMMW\\Anouk\\Venlo_8.mp4\",\n",
    "    conf=0.25,\n",
    "    classes= 0,\n",
    "    save=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict one image in local PC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = r'U:\\AIMMW\\GJO\\Auto\\10%_images_test\\images\\exp1_43.jpg'\n",
    "\n",
    "results = model.predict(\n",
    "    source= img_path, \n",
    "    conf=0.5,\n",
    "    save=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict images in a folder and output bbox information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.36  Python-3.9.12 torch-1.13.1+cu117 CPU\n",
      "Model summary (fused): 168 layers, 3006233 parameters, 0 gradients, 8.1 GFLOPs\n",
      "\n",
      "image 1/1 \\\\tudelft.net\\staff-umbrella\\AIMMW\\Vietnam\\Vietnam_3_class_V4_original\\test\\images\\DJI_0010.jpg: 384x640 347.0ms\n",
      "Speed: 2.0ms pre-process, 347.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mC:\\D\\D\\User\\PythonProject\\deep_plastic_YoloV8\\checkpoints\\trained_weights\\Vietnam_3_class_V4_original\\img_pred_test\u001b[0m\n",
      "\n",
      "image 1/1 \\\\tudelft.net\\staff-umbrella\\AIMMW\\Vietnam\\Vietnam_3_class_V4_original\\test\\images\\DJI_0264.jpg: 384x640 1 ff_litter, 2 hyacinths, 9 ent_litters, 310.3ms\n",
      "Speed: 1.0ms pre-process, 310.3ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mC:\\D\\D\\User\\PythonProject\\deep_plastic_YoloV8\\checkpoints\\trained_weights\\Vietnam_3_class_V4_original\\img_pred_test\u001b[0m\n",
      "\n",
      "image 1/1 \\\\tudelft.net\\staff-umbrella\\AIMMW\\Vietnam\\Vietnam_3_class_V4_original\\test\\images\\DJI_0853.jpg: 384x640 2 ff_litters, 29 hyacinths, 221.7ms\n",
      "Speed: 2.0ms pre-process, 221.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mC:\\D\\D\\User\\PythonProject\\deep_plastic_YoloV8\\checkpoints\\trained_weights\\Vietnam_3_class_V4_original\\img_pred_test\u001b[0m\n",
      "\n",
      "image 1/1 \\\\tudelft.net\\staff-umbrella\\AIMMW\\Vietnam\\Vietnam_3_class_V4_original\\test\\images\\G0016376.JPG: 576x640 318.2ms\n",
      "Speed: 1.0ms pre-process, 318.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mC:\\D\\D\\User\\PythonProject\\deep_plastic_YoloV8\\checkpoints\\trained_weights\\Vietnam_3_class_V4_original\\img_pred_test\u001b[0m\n",
      "\n",
      "image 1/1 \\\\tudelft.net\\staff-umbrella\\AIMMW\\Vietnam\\Vietnam_3_class_V4_original\\test\\images\\G0030235.JPG: 576x640 1 ff_litter, 50 hyacinths, 5 ent_litters, 348.0ms\n",
      "Speed: 2.0ms pre-process, 348.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mC:\\D\\D\\User\\PythonProject\\deep_plastic_YoloV8\\checkpoints\\trained_weights\\Vietnam_3_class_V4_original\\img_pred_test\u001b[0m\n",
      "\n",
      "image 1/1 \\\\tudelft.net\\staff-umbrella\\AIMMW\\Vietnam\\Vietnam_3_class_V4_original\\test\\images\\G0040344.JPG: 640x576 13 hyacinths, 1 ent_litter, 339.1ms\n",
      "Speed: 1.0ms pre-process, 339.1ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mC:\\D\\D\\User\\PythonProject\\deep_plastic_YoloV8\\checkpoints\\trained_weights\\Vietnam_3_class_V4_original\\img_pred_test\u001b[0m\n",
      "\n",
      "image 1/1 \\\\tudelft.net\\staff-umbrella\\AIMMW\\Vietnam\\Vietnam_3_class_V4_original\\test\\images\\G0045522.JPG: 576x640 1 ff_litter, 11 hyacinths, 297.3ms\n",
      "Speed: 1.0ms pre-process, 297.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mC:\\D\\D\\User\\PythonProject\\deep_plastic_YoloV8\\checkpoints\\trained_weights\\Vietnam_3_class_V4_original\\img_pred_test\u001b[0m\n",
      "\n",
      "image 1/1 \\\\tudelft.net\\staff-umbrella\\AIMMW\\Vietnam\\Vietnam_3_class_V4_original\\test\\images\\G0049872.JPG: 576x640 36 hyacinths, 1 ent_litter, 254.3ms\n",
      "Speed: 1.0ms pre-process, 254.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mC:\\D\\D\\User\\PythonProject\\deep_plastic_YoloV8\\checkpoints\\trained_weights\\Vietnam_3_class_V4_original\\img_pred_test\u001b[0m\n",
      "\n",
      "image 1/1 \\\\tudelft.net\\staff-umbrella\\AIMMW\\Vietnam\\Vietnam_3_class_V4_original\\test\\images\\G0095693.JPG: 576x640 2 ff_litters, 11 hyacinths, 2 ent_litters, 288.5ms\n",
      "Speed: 1.0ms pre-process, 288.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mC:\\D\\D\\User\\PythonProject\\deep_plastic_YoloV8\\checkpoints\\trained_weights\\Vietnam_3_class_V4_original\\img_pred_test\u001b[0m\n",
      "\n",
      "image 1/1 \\\\tudelft.net\\staff-umbrella\\AIMMW\\Vietnam\\Vietnam_3_class_V4_original\\test\\images\\G0100042.JPG: 576x640 6 hyacinths, 300.4ms\n",
      "Speed: 1.0ms pre-process, 300.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mC:\\D\\D\\User\\PythonProject\\deep_plastic_YoloV8\\checkpoints\\trained_weights\\Vietnam_3_class_V4_original\\img_pred_test\u001b[0m\n",
      "\n",
      "image 1/1 \\\\tudelft.net\\staff-umbrella\\AIMMW\\Vietnam\\Vietnam_3_class_V4_original\\test\\images\\G0106659.JPG: 576x640 4 hyacinths, 284.2ms\n",
      "Speed: 2.0ms pre-process, 284.2ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mC:\\D\\D\\User\\PythonProject\\deep_plastic_YoloV8\\checkpoints\\trained_weights\\Vietnam_3_class_V4_original\\img_pred_test\u001b[0m\n",
      "\n",
      "image 1/1 \\\\tudelft.net\\staff-umbrella\\AIMMW\\Vietnam\\Vietnam_3_class_V4_original\\test\\images\\G0145838.JPG: 576x640 2 ff_litters, 21 hyacinths, 299.2ms\n",
      "Speed: 1.0ms pre-process, 299.2ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mC:\\D\\D\\User\\PythonProject\\deep_plastic_YoloV8\\checkpoints\\trained_weights\\Vietnam_3_class_V4_original\\img_pred_test\u001b[0m\n",
      "\n",
      "image 1/1 \\\\tudelft.net\\staff-umbrella\\AIMMW\\Vietnam\\Vietnam_3_class_V4_original\\test\\images\\G0160224.JPG: 576x640 1 ff_litter, 12 hyacinths, 265.3ms\n",
      "Speed: 1.0ms pre-process, 265.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mC:\\D\\D\\User\\PythonProject\\deep_plastic_YoloV8\\checkpoints\\trained_weights\\Vietnam_3_class_V4_original\\img_pred_test\u001b[0m\n",
      "\n",
      "image 1/1 \\\\tudelft.net\\staff-umbrella\\AIMMW\\Vietnam\\Vietnam_3_class_V4_original\\test\\images\\G0568148.JPG: 576x640 14 hyacinths, 312.2ms\n",
      "Speed: 2.0ms pre-process, 312.2ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mC:\\D\\D\\User\\PythonProject\\deep_plastic_YoloV8\\checkpoints\\trained_weights\\Vietnam_3_class_V4_original\\img_pred_test\u001b[0m\n",
      "\n",
      "image 1/1 \\\\tudelft.net\\staff-umbrella\\AIMMW\\Vietnam\\Vietnam_3_class_V4_original\\test\\images\\G0621681.JPG: 576x640 25 hyacinths, 2 ent_litters, 268.3ms\n",
      "Speed: 1.0ms pre-process, 268.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mC:\\D\\D\\User\\PythonProject\\deep_plastic_YoloV8\\checkpoints\\trained_weights\\Vietnam_3_class_V4_original\\img_pred_test\u001b[0m\n",
      "\n",
      "image 1/1 \\\\tudelft.net\\staff-umbrella\\AIMMW\\Vietnam\\Vietnam_3_class_V4_original\\test\\images\\G0668474.JPG: 576x640 5 hyacinths, 425.1ms\n",
      "Speed: 3.0ms pre-process, 425.1ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mC:\\D\\D\\User\\PythonProject\\deep_plastic_YoloV8\\checkpoints\\trained_weights\\Vietnam_3_class_V4_original\\img_pred_test\u001b[0m\n",
      "\n",
      "image 1/1 \\\\tudelft.net\\staff-umbrella\\AIMMW\\Vietnam\\Vietnam_3_class_V4_original\\test\\images\\G0798890.JPG: 576x640 2 hyacinths, 375.0ms\n",
      "Speed: 4.0ms pre-process, 375.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mC:\\D\\D\\User\\PythonProject\\deep_plastic_YoloV8\\checkpoints\\trained_weights\\Vietnam_3_class_V4_original\\img_pred_test\u001b[0m\n",
      "\n",
      "image 1/1 \\\\tudelft.net\\staff-umbrella\\AIMMW\\Vietnam\\Vietnam_3_class_V4_original\\test\\images\\G0808899.JPG: 576x640 1 ff_litter, 28 hyacinths, 342.1ms\n",
      "Speed: 1.0ms pre-process, 342.1ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mC:\\D\\D\\User\\PythonProject\\deep_plastic_YoloV8\\checkpoints\\trained_weights\\Vietnam_3_class_V4_original\\img_pred_test\u001b[0m\n",
      "\n",
      "image 1/1 \\\\tudelft.net\\staff-umbrella\\AIMMW\\Vietnam\\Vietnam_3_class_V4_original\\test\\images\\G0822287.JPG: 576x640 5 hyacinths, 325.1ms\n",
      "Speed: 1.0ms pre-process, 325.1ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mC:\\D\\D\\User\\PythonProject\\deep_plastic_YoloV8\\checkpoints\\trained_weights\\Vietnam_3_class_V4_original\\img_pred_test\u001b[0m\n",
      "\n",
      "image 1/1 \\\\tudelft.net\\staff-umbrella\\AIMMW\\Vietnam\\Vietnam_3_class_V4_original\\test\\images\\G0828979.JPG: 576x640 1 ff_litter, 16 hyacinths, 326.1ms\n",
      "Speed: 3.0ms pre-process, 326.1ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mC:\\D\\D\\User\\PythonProject\\deep_plastic_YoloV8\\checkpoints\\trained_weights\\Vietnam_3_class_V4_original\\img_pred_test\u001b[0m\n",
      "\n",
      "image 1/1 \\\\tudelft.net\\staff-umbrella\\AIMMW\\Vietnam\\Vietnam_3_class_V4_original\\test\\images\\G0859085.JPG: 576x640 34 hyacinths, 2 ent_litters, 298.6ms\n",
      "Speed: 1.0ms pre-process, 298.6ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mC:\\D\\D\\User\\PythonProject\\deep_plastic_YoloV8\\checkpoints\\trained_weights\\Vietnam_3_class_V4_original\\img_pred_test\u001b[0m\n",
      "\n",
      "image 1/1 \\\\tudelft.net\\staff-umbrella\\AIMMW\\Vietnam\\Vietnam_3_class_V4_original\\test\\images\\G0909246.JPG: 576x640 1 ff_litter, 18 hyacinths, 1 ent_litter, 314.4ms\n",
      "Speed: 1.0ms pre-process, 314.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mC:\\D\\D\\User\\PythonProject\\deep_plastic_YoloV8\\checkpoints\\trained_weights\\Vietnam_3_class_V4_original\\img_pred_test\u001b[0m\n",
      "\n",
      "image 1/1 \\\\tudelft.net\\staff-umbrella\\AIMMW\\Vietnam\\Vietnam_3_class_V4_original\\test\\images\\G1204525.JPG: 576x640 2 ff_litters, 293.2ms\n",
      "Speed: 1.0ms pre-process, 293.2ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mC:\\D\\D\\User\\PythonProject\\deep_plastic_YoloV8\\checkpoints\\trained_weights\\Vietnam_3_class_V4_original\\img_pred_test\u001b[0m\n",
      "\n",
      "image 1/1 \\\\tudelft.net\\staff-umbrella\\AIMMW\\Vietnam\\Vietnam_3_class_V4_original\\test\\images\\G1224583.JPG: 576x640 2 ff_litters, 2 hyacinths, 461.8ms\n",
      "Speed: 6.0ms pre-process, 461.8ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mC:\\D\\D\\User\\PythonProject\\deep_plastic_YoloV8\\checkpoints\\trained_weights\\Vietnam_3_class_V4_original\\img_pred_test\u001b[0m\n",
      "\n",
      "image 1/1 \\\\tudelft.net\\staff-umbrella\\AIMMW\\Vietnam\\Vietnam_3_class_V4_original\\test\\images\\G1294806.JPG: 576x640 8 hyacinths, 3 ent_litters, 301.2ms\n",
      "Speed: 1.0ms pre-process, 301.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mC:\\D\\D\\User\\PythonProject\\deep_plastic_YoloV8\\checkpoints\\trained_weights\\Vietnam_3_class_V4_original\\img_pred_test\u001b[0m\n",
      "\n",
      "image 1/1 \\\\tudelft.net\\staff-umbrella\\AIMMW\\Vietnam\\Vietnam_3_class_V4_original\\test\\images\\G1344976.JPG: 576x640 8 hyacinths, 1 ent_litter, 505.1ms\n",
      "Speed: 2.0ms pre-process, 505.1ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mC:\\D\\D\\User\\PythonProject\\deep_plastic_YoloV8\\checkpoints\\trained_weights\\Vietnam_3_class_V4_original\\img_pred_test\u001b[0m\n",
      "\n",
      "image 1/1 \\\\tudelft.net\\staff-umbrella\\AIMMW\\Vietnam\\Vietnam_3_class_V4_original\\test\\images\\G1415215.JPG: 576x640 18 hyacinths, 1 ent_litter, 300.7ms\n",
      "Speed: 2.0ms pre-process, 300.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mC:\\D\\D\\User\\PythonProject\\deep_plastic_YoloV8\\checkpoints\\trained_weights\\Vietnam_3_class_V4_original\\img_pred_test\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import utils.bbox as bb\n",
    "\n",
    "# Note: it should be the \"test images\" path, not \"test dataset\" path\n",
    "folder_path = r\"U:\\AIMMW\\Vietnam\\Vietnam_3_class_V4_original\\test\\images\"\n",
    "\n",
    "# output results in an excel file\n",
    "excel_path=r\"C:\\D\\D\\User\\PythonProject\\deep_plastic_YoloV8\\checkpoints\\trained_weights\\Vietnam_3_class_V4_original\\img_pred_test.xlsx\"\n",
    "\n",
    "# do not creat this folder, the code will create it automatically.\n",
    "save_test_images_dir = r\"C:\\D\\D\\User\\PythonProject\\deep_plastic_YoloV8\\checkpoints\\trained_weights\\Vietnam_3_class_V4_original\\img_pred_test\"\n",
    "\n",
    "filename_list=[] # for saving detailed bbox info \n",
    "xmin_list=[]\n",
    "ymin_list=[]\n",
    "xmax_list=[]\n",
    "ymax_list=[]\n",
    "conf_list=[]\n",
    "class_bbox_list=[]\n",
    "area_bbox_list=[]\n",
    "\n",
    "\n",
    "filename_list_2=[] # for saving No.bbox info \n",
    "\n",
    "# define the number of classes \n",
    "num_classes = 3\n",
    "num_0_list=[]\n",
    "num_1_list=[]\n",
    "num_2_list=[]\n",
    "\n",
    "for filename in os.listdir(folder_path):\n",
    "   num_0 = 0\n",
    "   num_1 = 0\n",
    "   num_2 = 0\n",
    "    \n",
    "   #  if not filename.endswith('.jpg'): continue\n",
    "   #  if not filename.endswith((\".jpg\", \".JPG\")): continue\n",
    "   if filename.endswith((\".jpg\", \".jpeg\", \".png\", \".JPG\")):\n",
    "      img_path = os.path.join(folder_path, filename)\n",
    "      # predict each image\n",
    "      results = model.predict(\n",
    "                           source= img_path, \n",
    "                           conf=0.5,\n",
    "                           save=True,\n",
    "                           # save=False,\n",
    "                           name=save_test_images_dir\n",
    "                           )\n",
    "    \n",
    "    \n",
    "      boxes = results[0].boxes\n",
    "    \n",
    "      # capture detailed bbox information\n",
    "      for i in range(boxes.__len__()):\n",
    "         xyxy = boxes[i].xyxy.cpu().numpy()\n",
    "         xmin = xyxy[0][0]\n",
    "         ymin = xyxy[0][1]\n",
    "         xmax = xyxy[0][2]\n",
    "         ymax = xyxy[0][3]\n",
    "         conf = boxes[i].conf.cpu().numpy()[0]\n",
    "         class_bbox = boxes[i].cls.cpu().numpy()[0]\n",
    "         area_bbox = (xmax-xmin)*(ymax-ymin)\n",
    "\n",
    "         filename_list.append(filename)\n",
    "         xmin_list.append(xmin)\n",
    "         ymin_list.append(ymin)\n",
    "         xmax_list.append(xmax)\n",
    "         ymax_list.append(ymax)\n",
    "         conf_list.append(conf)\n",
    "         class_bbox_list.append(class_bbox)\n",
    "         area_bbox_list.append(area_bbox)\n",
    "    \n",
    "    # capture No.bbox information   \n",
    "      for j in range(boxes.__len__()):\n",
    "         class_bbox = boxes[j].cls.cpu().numpy()[0]\n",
    "         if class_bbox == 0.0:\n",
    "           num_0 = num_0 + 1\n",
    "         if class_bbox == 1.0:\n",
    "           num_1 = num_1 + 1\n",
    "         if class_bbox == 2.0:\n",
    "           num_2 = num_2 + 1\n",
    "    \n",
    "      filename_list_2.append(filename)\n",
    "      num_0_list.append(num_0)\n",
    "      num_1_list.append(num_1)\n",
    "      num_2_list.append(num_2)\n",
    "\n",
    "# save detailed bbox info in a excel file       \n",
    "bb.save_bbox_info_in_excel(excel_path, \"Sheet1\", filename_list, \n",
    "         xmin_list, ymin_list, xmax_list, ymax_list, conf_list, class_bbox_list, area_bbox_list)\n",
    "\n",
    "# save No.bbox info in a excel file  \n",
    "bb.save_num__bbox_in_excel(excel_path, \"Sheet2\", filename_list_2, num_classes, num_0_list, num_1_list, num_2_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# area_bbox_list"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict images and output the number of litter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils.bbox as bb\n",
    "import os\n",
    "\n",
    "# Note: it should be the \"test images\" path, not \"test dataset\" path\n",
    "folder_path = r\"U:\\AIMMW\\Vietnam\\TimJanssen_FullDataset\\0_tiles\"\n",
    "\n",
    "# output results in an excel file\n",
    "excel_path=r\"U:\\AIMMW\\Vietnam\\TimJanssen_FullDataset\\0_tiles.xlsx\"\n",
    "\n",
    "\n",
    "# save_test_images_dir = r\"F:\\Tianlong\\PythonProject\\deep_plastic_YoloV8\\checkpoints\\trained_weights\\Vietnam_3_class_V3_200e\\test\\images_pred_3_class\"\n",
    "\n",
    "filename_list=[]\n",
    "\n",
    "# define the number of classes \n",
    "num_classes = 3\n",
    "num_0_list=[]\n",
    "num_1_list=[]\n",
    "num_2_list=[]\n",
    "\n",
    "for filename in os.listdir(folder_path):\n",
    "   num_0 = 0\n",
    "   num_1 = 0\n",
    "   num_2 = 0\n",
    "    \n",
    "   # if not filename.endswith('.jpg'): continue\n",
    "   img_path = os.path.join(folder_path, filename)\n",
    "   # predict each image\n",
    "   results = model.predict(\n",
    "                           source= img_path, \n",
    "                           conf=0.5,\n",
    "                           save=False\n",
    "                           # name=save_test_images_dir\n",
    "                           )\n",
    "    \n",
    "   # capture bbox information\n",
    "   boxes = results[0].boxes\n",
    "\n",
    "   for i in range(boxes.__len__()):\n",
    "        class_bbox = boxes[i].cls.cpu().numpy()[0]\n",
    "        if class_bbox == 0.0:\n",
    "           num_0 = num_0 + 1\n",
    "        if class_bbox == 1.0:\n",
    "           num_1 = num_1 + 1\n",
    "        if class_bbox == 2.0:\n",
    "           num_2 = num_2 + 1\n",
    "\n",
    "   filename_list.append(filename)\n",
    "   num_0_list.append(num_0)\n",
    "   num_1_list.append(num_1)\n",
    "   num_2_list.append(num_2)\n",
    "\n",
    "\n",
    "\n",
    "# save bbox info in a excel file       \n",
    "bb.save_num__bbox_in_excel(excel_path, \"Sheet2\", filename_list, num_classes, num_0_list, num_1_list, num_2_list)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "YoloV8_DP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f74d253e4eb56f30f9876e3386f420476fae3ba0f785ecd20d405a135215bce6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
